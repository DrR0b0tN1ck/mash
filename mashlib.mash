[[[
# vim: set ft=python :

import concurrent.futures
import os
import resource
import shutil
import subprocess
import sys
import re
import filecmp
import glob
import hashlib


from exceptiongroup import ExceptionGroup

# A library of "standard" functions that provide many of the basic operations
# that one might want to do on a mash frame.  Most mash documents will include
# this near the start.

# First, some initialization.  This should only happen once.
try:
    mashlib_initialized
except NameError:
    mashlib_initialized = False

if not mashlib_initialized:
    mashlib_initialized = True

    # A list of executable names whose existence we have already verified.
    executables_checked = set()

    # A limit on the number of parallel jobs to run at a time.
    max_jobs = os.cpu_count() + 4

    # The manager for the thread pool that handles expensive jobs, mostly from
    # shell().  Created on the first call that needs it, rather than here, to
    # give the client code time to change max_jobs.
    job_executor = None

    # A list of futures for jobs that have been submitted.
    job_futures = []

    # This is the directory where started.
    original_directory = os.getcwd()
    sys.path.append(original_directory)

    # This is the directory where we will do all of our work, execute commands,
    # etc.  This will be the current directory most of the time.
    build_directory = os.path.join(original_directory, ".mash")
    sys.path.append(build_directory)

    # This directory has things built in previous runs.  If nothing has
    # changed, then we can just copy things over from there instead of
    # re-building them.
    archive_directory = os.path.join(original_directory, ".mash-archive")

    # This is the directory that should contain the completed output files.
    keep_directory = original_directory

    # This is a list of places we should search when importing a new file.
    import_search_directories = [original_directory, ]

    # Move anything from the existing build directory to the archive directory.
    if os.path.exists(build_directory):
        for file_name in os.listdir(build_directory):
          if not os.path.exists(archive_directory):
              os.makedirs(archive_directory)
          full_file_name = os.path.join(build_directory, file_name)
          full_file_name_archive = os.path.join(archive_directory, file_name)
          if os.path.isdir(full_file_name_archive):
              shutil.rmtree(full_file_name_archive)
          #print("%s --> %s" % (full_file_name, archive_directory))
          shutil.move(full_file_name, os.path.join(archive_directory, file_name))

    # Make sure we have a build directory and that it's the current/working
    # directory.
    if not os.path.exists(build_directory):
        #print("Creating", build_directory)
        os.makedirs(build_directory)
    os.chdir(build_directory)

def check_for_executable(exe):
    """Check whether some executable with the given name exists in the path.
    If it does not exist, complain."""
    if exe not in executables_checked and shutil.which(exe) is None:
        raise ValueError(f'Executable {exe} not found in path.')
    executables_checked.add(exe)

def shell(command, stdin=None, check=True):
    """Execute the given command in a shell.  Raise
    subprocess.CalledProcessError if the command gives a non-zero return code.
    Return the CompletedProcess object, which has stdout and stderr attributes.
    In addition, this object has attributes tacked on to it showing the user
    time and system time consumed, as reported by getrusage."""
    global job_executor
    
    if job_executor is None:
        job_executor = concurrent.futures.ThreadPoolExecutor(max_workers=max_jobs)

    if check:
        check_for_executable(command.split(' ')[0])

    print("  ", command)

    def run_job():
        usage_before = resource.getrusage(resource.RUSAGE_CHILDREN)

        completed_process = subprocess.run(command,
                                           shell=True,
                                           check=True,
                                           input=stdin,
                                           stdout=subprocess.PIPE,
                                           stderr=subprocess.PIPE,
                                           timeout=60000)
        usage_after = resource.getrusage(resource.RUSAGE_CHILDREN)
        completed_process.user_time = usage_after.ru_utime - usage_before.ru_utime
        completed_process.sys_time = usage_after.ru_stime - usage_before.ru_stime
        
        return completed_process

    future = job_executor.submit(run_job)
    job_futures.append(future)

def at_end():
    # Finish up any jobs that are still running.
    exceptions = []
    for future in job_futures:
        try:
            future.result()
        except Exception as exception:
            exceptions.append(exception)

    # Report any exceptions that occured.
    if len(exceptions) == 1:
        raise exceptions[0]
    elif len(exceptions) > 1:
        raise ExceptionGroup("multiple failed jobs", exceptions)

]]]

